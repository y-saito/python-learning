# 作業報告書

- 作成日時: 2026-02-21 14:58:48
- 対象プロジェクト: `python-learning`
- 報告範囲: データ処理キャッチアップ計画の補完（JSON/Parquet・ETL追加）

## 1. 今回の目的

Python の本領であるデータ処理分野の学習を開始するにあたり、
PHP・Node.js の実装経験と比較しながら、Python が得意なポイントを明確にする。

## 2. 進め方の前提（比較方針）

各行程で以下を必ずセットで整理する。

1. Node.js での一般的なやり方
2. PHP での一般的なやり方
3. Python でのやり方
4. Python が優位になりやすい理由（ライブラリ・記述量・分析しやすさ）

## 3. データ処理の基本を学ぶお題

### お題1: CSV 売上データの集計（基礎）

- 内容:
  - `date, product, category, quantity, price` を持つ CSV を読み込み、
    日次売上・カテゴリ別売上・上位商品を集計する。
- Node.js 比較:
  - `csv-parse` + 配列操作（`reduce`）で実装。
- PHP 比較:
  - `fgetcsv` + 配列ループで実装。
- Python でのやり方:
  - `pandas.read_csv()` + `groupby()` + `agg()` で集計。
- Python が得意な点:
  - 集計コードが短く、複数観点の集計を同じデータフレーム上で連続実行しやすい。

### お題2: JSON ログの整形と異常値検出（前処理）

- 内容:
  - API ログ（JSON Lines）を読み込み、
    欠損補完、型変換、レスポンス時間の外れ値検出を行う。
- Node.js 比較:
  - JSON パース後に手続き的ループでバリデーション・変換。
- PHP 比較:
  - `json_decode` 後に配列処理で変換・検証。
- Python でのやり方:
  - `pandas.json_normalize()`、`to_datetime()`、統計量（IQR/Z-score）で異常値判定。
- Python が得意な点:
  - 前処理関数が豊富で、分析前のクリーニングを一貫した流れで実行できる。

### お題3: 複数データの結合（JOIN 相当）

- 内容:
  - `customers.csv` と `orders.csv` を結合し、
    顧客セグメント別の購入傾向を分析する。
- Node.js 比較:
  - Map を作って疑似 JOIN を手実装することが多い。
- PHP 比較:
  - 配列インデックスを構築して突合する実装になりやすい。
- Python でのやり方:
  - `pandas.merge()` で INNER/LEFT JOIN を明示して結合。
- Python が得意な点:
  - 結合条件や欠損行の扱いを宣言的に書けて、検証がしやすい。

### お題4: SQL 連携と分析クエリ（実務寄り）

- 内容:
  - PostgreSQL のテーブルからデータ取得し、
    Python 側で再集計してレポート出力する。
- Node.js 比較:
  - `pg` で取得後、アプリ側で整形処理。
- PHP 比較:
  - PDO で取得後、配列操作で集計。
- Python でのやり方:
  - `sqlalchemy` または `pandas.read_sql()` で取得し、DataFrame で集計。
- Python が得意な点:
  - SQL と分析処理の境界が扱いやすく、探索的分析から定型レポート化へ移行しやすい。

### お題5: 可視化によるレポート化（出力）

- 内容:
  - 集計結果をグラフ化し、意思決定向けの簡易レポートを作成する。
- Node.js 比較:
  - サーバー側のみだと可視化は追加ライブラリやフロント実装が必要。
- PHP 比較:
  - Web 表示前提の可視化になりやすく、分析試行回数が増えると手間が増える。
- Python でのやり方:
  - `matplotlib` / `seaborn` で素早く可視化し、画像や HTML で出力。
- Python が得意な点:
  - 分析・可視化・レポート化を同じ言語・同じデータ構造で完結しやすい。

### お題6: データ形式の基礎（JSON / Parquet の読み込み比較）

- 内容:
  - 同一内容の `sales.json` と `sales.parquet` を読み込み、
    `CSV` と同じ集計（件数、売上合計、カテゴリ別売上）を実行して差分を確認する。
- Node.js 比較:
  - JSON は `JSON.parse` で扱いやすいが、Parquet は追加ライブラリ導入とスキーマ意識が必要。
- PHP 比較:
  - JSON は `json_decode` で処理可能だが、Parquet は実装選択肢が少なく運用難度が上がりやすい。
- Python でのやり方:
  - `pandas.read_json()` と `pandas.read_parquet()` で統一的に DataFrame 化して同じ集計コードを再利用。
- Python が得意な点:
  - ファイル形式が変わっても集計ロジックをほぼ変えずに流用できる。

### お題7: ETLミニパイプライン（用語理解 + 実装）

- 内容:
  - 1本のミニ処理として、`Extract -> Transform -> Load` を明示して実装する。
  - 例: `orders.csv` を読み込み（Extract）、欠損補完と型変換を実行（Transform）、`clean_orders.parquet` に保存（Load）。
- Node.js 比較:
  - スクリプト分割で ETL を表現しやすいが、データ変換の記述が手続き的になりやすい。
- PHP 比較:
  - バッチ処理として ETL は可能だが、分析向け変換の再利用性は設計次第で差が出やすい。
- Python でのやり方:
  - `pandas` を中心に 1つのノートブックまたはスクリプトで ETL を明示し、処理段階ごとに関数化する。
- Python が得意な点:
  - ETL の各段階を短く記述でき、検証（件数確認・欠損確認）を挟みやすい。

## 4. 初回実施順（推奨）

1. お題1（CSV 集計）
2. お題2（前処理・異常値）
3. お題6（JSON / Parquet 形式）
4. お題3（結合）
5. お題4（SQL 連携）
6. お題7（ETL ミニパイプライン）
7. お題5（可視化）

この順に進めることで、データ処理の基本（形式理解 -> 読み込み -> 整形 -> 結合 -> ETL -> 出力）を一連で学べる。

## 5. 次アクション

- 次回はお題1を実装し、同じ入力データに対して Node.js / PHP / Python の3実装を最小構成で並べて比較する。
- 第3章の進行に合わせて、お題6（JSON/Parquet）とお題7（ETL）を差し込み、動画外の試験範囲を補完する。
- 比較観点は以下の3点で固定する。
  - 実装コード量
  - 可読性（意図が読み取りやすいか）
  - 拡張性（列追加・集計観点追加への対応しやすさ）
